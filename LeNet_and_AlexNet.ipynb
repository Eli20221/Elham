{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogVY0Bz70Gmb",
        "outputId": "0a6cbe3a-6de5-4806-af7e-05b85a07d4ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "\n",
        "(x_train, y_train), (x_test, y_test)  = mnist.load_data()\n",
        "\n",
        "img_rows = x_train[0].shape[0]\n",
        "img_cols = x_train[1].shape[0]\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "num_classes = y_test.shape[1]\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(6, (5, 5),\n",
        "                 padding = \"same\", \n",
        "                 input_shape = input_shape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(16, (5, 5),\n",
        "                 padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(120, (5, 5),\n",
        "                 padding = \"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(120))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Dense(84))\n",
        "model.add(Activation(\"relu\"))\n",
        "# Softmax (for classification)\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "           \n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = Adadelta(),\n",
        "              metrics = ['accuracy'])\n",
        "    \n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKIXQD5T0X3a",
        "outputId": "d99f4c2e-3076-4210-e424-006aca303245"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 6)         156       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 28, 28, 6)         0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 6)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 14, 14, 16)        2416      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 14, 14, 16)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 7, 7, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 7, 7, 120)         48120     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 7, 7, 120)         0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 3, 3, 120)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1080)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 120)               129720    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 120)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 84)                10164     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 84)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 191,426\n",
            "Trainable params: 191,426\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)\n",
        "\n",
        "model.save(\"mnist_LeNet.h5\")\n",
        "\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrXT8nGF0ntQ",
        "outputId": "fd20fe64-7691-4f9b-def8-9e59b6b03a99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 17s 7ms/step - loss: 2.3035 - accuracy: 0.1114 - val_loss: 2.2977 - val_accuracy: 0.1257\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 2.2909 - accuracy: 0.1696 - val_loss: 2.2840 - val_accuracy: 0.2457\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 2.2770 - accuracy: 0.2833 - val_loss: 2.2695 - val_accuracy: 0.3192\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 2.2617 - accuracy: 0.3372 - val_loss: 2.2525 - val_accuracy: 0.3647\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 2.2432 - accuracy: 0.4012 - val_loss: 2.2316 - val_accuracy: 0.4289\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 2.2203 - accuracy: 0.4526 - val_loss: 2.2053 - val_accuracy: 0.4858\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 2.1906 - accuracy: 0.4968 - val_loss: 2.1706 - val_accuracy: 0.5287\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 2.1512 - accuracy: 0.5333 - val_loss: 2.1242 - val_accuracy: 0.5621\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 2.0980 - accuracy: 0.5610 - val_loss: 2.0611 - val_accuracy: 0.5967\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 2.0259 - accuracy: 0.5878 - val_loss: 1.9759 - val_accuracy: 0.6161\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 1.9297 - accuracy: 0.6090 - val_loss: 1.8639 - val_accuracy: 0.6406\n",
            "Epoch 12/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.8064 - accuracy: 0.6401 - val_loss: 1.7239 - val_accuracy: 0.6668\n",
            "Epoch 13/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.6578 - accuracy: 0.6709 - val_loss: 1.5619 - val_accuracy: 0.7034\n",
            "Epoch 14/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.4946 - accuracy: 0.7049 - val_loss: 1.3928 - val_accuracy: 0.7348\n",
            "Epoch 15/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.3325 - accuracy: 0.7378 - val_loss: 1.2338 - val_accuracy: 0.7602\n",
            "Epoch 16/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 1.1856 - accuracy: 0.7660 - val_loss: 1.0948 - val_accuracy: 0.7894\n",
            "Epoch 17/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 1.0596 - accuracy: 0.7862 - val_loss: 0.9795 - val_accuracy: 0.8085\n",
            "Epoch 18/50\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.9568 - accuracy: 0.8005 - val_loss: 0.8876 - val_accuracy: 0.8197\n",
            "Epoch 19/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.8744 - accuracy: 0.8110 - val_loss: 0.8143 - val_accuracy: 0.8296\n",
            "Epoch 20/50\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.8077 - accuracy: 0.8195 - val_loss: 0.7550 - val_accuracy: 0.8362\n",
            "Epoch 21/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.7534 - accuracy: 0.8280 - val_loss: 0.7062 - val_accuracy: 0.8415\n",
            "Epoch 22/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.7081 - accuracy: 0.8346 - val_loss: 0.6655 - val_accuracy: 0.8485\n",
            "Epoch 23/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.6698 - accuracy: 0.8409 - val_loss: 0.6310 - val_accuracy: 0.8532\n",
            "Epoch 24/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.6368 - accuracy: 0.8464 - val_loss: 0.6010 - val_accuracy: 0.8590\n",
            "Epoch 25/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.6079 - accuracy: 0.8517 - val_loss: 0.5746 - val_accuracy: 0.8632\n",
            "Epoch 26/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.5825 - accuracy: 0.8566 - val_loss: 0.5513 - val_accuracy: 0.8670\n",
            "Epoch 27/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.5598 - accuracy: 0.8611 - val_loss: 0.5304 - val_accuracy: 0.8706\n",
            "Epoch 28/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.5394 - accuracy: 0.8654 - val_loss: 0.5119 - val_accuracy: 0.8741\n",
            "Epoch 29/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.5207 - accuracy: 0.8694 - val_loss: 0.4944 - val_accuracy: 0.8764\n",
            "Epoch 30/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.5038 - accuracy: 0.8723 - val_loss: 0.4788 - val_accuracy: 0.8793\n",
            "Epoch 31/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4882 - accuracy: 0.8755 - val_loss: 0.4646 - val_accuracy: 0.8827\n",
            "Epoch 32/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4739 - accuracy: 0.8786 - val_loss: 0.4511 - val_accuracy: 0.8860\n",
            "Epoch 33/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4605 - accuracy: 0.8814 - val_loss: 0.4386 - val_accuracy: 0.8874\n",
            "Epoch 34/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.4482 - accuracy: 0.8837 - val_loss: 0.4271 - val_accuracy: 0.8912\n",
            "Epoch 35/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4365 - accuracy: 0.8860 - val_loss: 0.4164 - val_accuracy: 0.8951\n",
            "Epoch 36/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4258 - accuracy: 0.8884 - val_loss: 0.4062 - val_accuracy: 0.8972\n",
            "Epoch 37/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4157 - accuracy: 0.8907 - val_loss: 0.3966 - val_accuracy: 0.8993\n",
            "Epoch 38/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.4061 - accuracy: 0.8923 - val_loss: 0.3877 - val_accuracy: 0.9011\n",
            "Epoch 39/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.3970 - accuracy: 0.8950 - val_loss: 0.3786 - val_accuracy: 0.9027\n",
            "Epoch 40/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3882 - accuracy: 0.8967 - val_loss: 0.3709 - val_accuracy: 0.9041\n",
            "Epoch 41/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3800 - accuracy: 0.8989 - val_loss: 0.3631 - val_accuracy: 0.9065\n",
            "Epoch 42/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3722 - accuracy: 0.9007 - val_loss: 0.3555 - val_accuracy: 0.9078\n",
            "Epoch 43/50\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.3649 - accuracy: 0.9021 - val_loss: 0.3487 - val_accuracy: 0.9093\n",
            "Epoch 44/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3578 - accuracy: 0.9039 - val_loss: 0.3419 - val_accuracy: 0.9107\n",
            "Epoch 45/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3511 - accuracy: 0.9049 - val_loss: 0.3361 - val_accuracy: 0.9119\n",
            "Epoch 46/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3447 - accuracy: 0.9064 - val_loss: 0.3294 - val_accuracy: 0.9134\n",
            "Epoch 47/50\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.3386 - accuracy: 0.9085 - val_loss: 0.3236 - val_accuracy: 0.9147\n",
            "Epoch 48/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3328 - accuracy: 0.9090 - val_loss: 0.3180 - val_accuracy: 0.9157\n",
            "Epoch 49/50\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.3272 - accuracy: 0.9104 - val_loss: 0.3125 - val_accuracy: 0.9173\n",
            "Epoch 50/50\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.3218 - accuracy: 0.9116 - val_loss: 0.3078 - val_accuracy: 0.9181\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.3078 - accuracy: 0.9181\n",
            "Test loss: 0.3078062832355499\n",
            "Test accuracy: 0.9180999994277954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "num_classes = 10\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rp05DMX0usr",
        "outputId": "a8571e81-282b-4e69-f44e-32eae55d1559"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l2_reg = 0.001\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(96, (11, 11), input_shape=x_train.shape[1:],\n",
        "    padding='same', kernel_regularizer=l2(l2_reg)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (5, 5), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(ZeroPadding2D((1, 1)))\n",
        "model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(ZeroPadding2D((1, 1)))\n",
        "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(ZeroPadding2D((1, 1)))\n",
        "model.add(Conv2D(1024, (3, 3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3072))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(4096))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(num_classes))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy',\n",
        "              optimizer = Adadelta(),\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TdID5vR02Zw",
        "outputId": "e9312238-fc68-4236-8164-4b6d38b3bb96"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 32, 32, 96)        34944     \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 96)       384       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 32, 32, 96)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 16, 16, 96)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 16, 16, 256)       614656    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 8, 8, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " zero_padding2d (ZeroPadding  (None, 10, 10, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 10, 10, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 10, 10, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 10, 10, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 5, 5, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " zero_padding2d_1 (ZeroPaddi  (None, 7, 7, 512)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 7, 7, 1024)        4719616   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 7, 7, 1024)       4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 7, 7, 1024)        0         \n",
            "                                                                 \n",
            " zero_padding2d_2 (ZeroPaddi  (None, 9, 9, 1024)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 9, 9, 1024)        9438208   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 9, 9, 1024)       4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 9, 9, 1024)        0         \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 4, 4, 1024)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 16384)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 3072)              50334720  \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 3072)             12288     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 3072)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4096)              12587008  \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 4096)             16384     \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 4096)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                40970     \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 10)               40        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 78,990,642\n",
            "Trainable params: 78,970,462\n",
            "Non-trainable params: 20,180\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 64\n",
        "epochs = 25\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          shuffle=True)\n",
        "\n",
        "model.save(\"CIFAR10_AlexNet_10_Epoch.h5\")\n",
        "\n",
        "\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3jjkZ3h1Es0",
        "outputId": "da1b3543-72e0-44c3-d4a7-e92503f317ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "782/782 [==============================] - 96s 109ms/step - loss: 2.1356 - accuracy: 0.2449 - val_loss: 1.7617 - val_accuracy: 0.3920\n",
            "Epoch 2/25\n",
            "782/782 [==============================] - 84s 107ms/step - loss: 1.8409 - accuracy: 0.3447 - val_loss: 1.6612 - val_accuracy: 0.4321\n",
            "Epoch 3/25\n",
            "782/782 [==============================] - 83s 107ms/step - loss: 1.7411 - accuracy: 0.3864 - val_loss: 1.5970 - val_accuracy: 0.4605\n",
            "Epoch 4/25\n",
            "782/782 [==============================] - 83s 106ms/step - loss: 1.6729 - accuracy: 0.4174 - val_loss: 1.5536 - val_accuracy: 0.4747\n",
            "Epoch 5/25\n",
            "782/782 [==============================] - 83s 107ms/step - loss: 1.6285 - accuracy: 0.4357 - val_loss: 1.5158 - val_accuracy: 0.4923\n",
            "Epoch 6/25\n",
            "782/782 [==============================] - 83s 107ms/step - loss: 1.5852 - accuracy: 0.4569 - val_loss: 1.4864 - val_accuracy: 0.5036\n",
            "Epoch 7/25\n",
            "782/782 [==============================] - 83s 106ms/step - loss: 1.5539 - accuracy: 0.4730 - val_loss: 1.4639 - val_accuracy: 0.5159\n",
            "Epoch 8/25\n",
            "782/782 [==============================] - 83s 107ms/step - loss: 1.5243 - accuracy: 0.4844 - val_loss: 1.4428 - val_accuracy: 0.5246\n",
            "Epoch 9/25\n",
            "782/782 [==============================] - 83s 107ms/step - loss: 1.5010 - accuracy: 0.5008 - val_loss: 1.4236 - val_accuracy: 0.5328\n",
            "Epoch 10/25\n",
            "782/782 [==============================] - 84s 107ms/step - loss: 1.4772 - accuracy: 0.5084 - val_loss: 1.4109 - val_accuracy: 0.5422\n",
            "Epoch 11/25\n",
            "782/782 [==============================] - 84s 107ms/step - loss: 1.4599 - accuracy: 0.5173 - val_loss: 1.3925 - val_accuracy: 0.5498\n",
            "Epoch 12/25\n",
            "782/782 [==============================] - 84s 107ms/step - loss: 1.4400 - accuracy: 0.5286 - val_loss: 1.3784 - val_accuracy: 0.5584\n",
            "Epoch 13/25\n",
            "782/782 [==============================] - 84s 107ms/step - loss: 1.4189 - accuracy: 0.5393 - val_loss: 1.3669 - val_accuracy: 0.5623\n",
            "Epoch 14/25\n",
            "782/782 [==============================] - 83s 107ms/step - loss: 1.4021 - accuracy: 0.5472 - val_loss: 1.3607 - val_accuracy: 0.5628\n",
            "Epoch 15/25\n",
            "782/782 [==============================] - 84s 107ms/step - loss: 1.3852 - accuracy: 0.5530 - val_loss: 1.3457 - val_accuracy: 0.5698\n",
            "Epoch 16/25\n",
            "782/782 [==============================] - 84s 107ms/step - loss: 1.3687 - accuracy: 0.5642 - val_loss: 1.3373 - val_accuracy: 0.5734\n",
            "Epoch 17/25\n",
            "782/782 [==============================] - 83s 107ms/step - loss: 1.3540 - accuracy: 0.5720 - val_loss: 1.3227 - val_accuracy: 0.5780\n",
            "Epoch 18/25\n",
            "782/782 [==============================] - 83s 106ms/step - loss: 1.3403 - accuracy: 0.5796 - val_loss: 1.3192 - val_accuracy: 0.5847\n",
            "Epoch 19/25\n",
            "782/782 [==============================] - 83s 107ms/step - loss: 1.3232 - accuracy: 0.5888 - val_loss: 1.3109 - val_accuracy: 0.5865\n",
            "Epoch 20/25\n",
            "782/782 [==============================] - 84s 107ms/step - loss: 1.3112 - accuracy: 0.5931 - val_loss: 1.3000 - val_accuracy: 0.5896\n",
            "Epoch 21/25\n",
            "782/782 [==============================] - 83s 107ms/step - loss: 1.2972 - accuracy: 0.6001 - val_loss: 1.2945 - val_accuracy: 0.5929\n",
            "Epoch 22/25\n",
            "782/782 [==============================] - 83s 106ms/step - loss: 1.2835 - accuracy: 0.6043 - val_loss: 1.2858 - val_accuracy: 0.6015\n",
            "Epoch 23/25\n",
            "782/782 [==============================] - 83s 107ms/step - loss: 1.2732 - accuracy: 0.6119 - val_loss: 1.2758 - val_accuracy: 0.6036\n",
            "Epoch 24/25\n",
            "782/782 [==============================] - 84s 107ms/step - loss: 1.2580 - accuracy: 0.6190 - val_loss: 1.2732 - val_accuracy: 0.6058\n",
            "Epoch 25/25\n",
            "782/782 [==============================] - 83s 106ms/step - loss: 1.2430 - accuracy: 0.6281 - val_loss: 1.2689 - val_accuracy: 0.6066\n",
            "313/313 [==============================] - 7s 20ms/step - loss: 1.2689 - accuracy: 0.6066\n",
            "Test loss: 1.2688812017440796\n",
            "Test accuracy: 0.6065999865531921\n"
          ]
        }
      ]
    }
  ]
}